import os
import numpy as np

# === é…ç½®è·¯å¾„ ===
data_dir = "/root/autodl-tmp/dataset/calvin_debug_dataset/training"
lang_path = os.path.join(data_dir, "lang_annotations/auto_lang_ann.npy")

# === åŠ è½½è¯­è¨€æ ‡æ³¨ ===
lang_data = np.load(lang_path, allow_pickle=True).item()
lang_ranges = lang_data["info"]["indx"]  # e.g. [(358656, 358720), ...]

# å°†æ‰€æœ‰æœ‰æ ‡æ³¨çš„ episode id æ”¶é›†æˆä¸€ä¸ªé›†åˆï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾
annotated_eps = set()
for start, end in lang_ranges:
    annotated_eps.update(range(start, end))

print(f"ğŸ“š ä»è¯­è¨€æ ‡æ³¨ä¸­åŠ è½½åˆ° {len(lang_ranges)} ä¸ªåŒºé—´ï¼Œå…±è¦†ç›– {len(annotated_eps)} ä¸ª episode id\n")

# === æ‰«æ npz æ–‡ä»¶ ===
npz_files = sorted(f for f in os.listdir(data_dir) if f.endswith(".npz"))
total = len(npz_files)
missing = 0
covered = 0

missing_list = []

for npz in npz_files:
    try:
        ep_id = int(npz.split("_")[1].split(".")[0])
    except Exception:
        continue  # è·³è¿‡å‘½åä¸è§„èŒƒçš„æ–‡ä»¶

    if ep_id not in annotated_eps:
        missing += 1
        missing_list.append(ep_id)
    else:
        covered += 1

# === è¾“å‡ºç»Ÿè®¡ç»“æœ ===
print("ğŸ“Š æ£€æµ‹ç»“æœï¼š")
print(f"  âœ… æœ‰è¯­è¨€æ ‡æ³¨çš„ episode æ•°é‡: {covered}")
print(f"  âš ï¸ æ— è¯­è¨€æ ‡æ³¨çš„ episode æ•°é‡: {missing}")
print(f"  æ€»è®¡ .npz æ–‡ä»¶æ•°: {total}")

if missing > 0:
    print("\nğŸ” ç¤ºä¾‹ç¼ºå¤±çš„ episode idï¼ˆå‰10ä¸ªï¼‰:")
    print(missing_list[:10])

coverage = covered / total * 100 if total > 0 else 0
print(f"\nğŸ“ˆ è¦†ç›–ç‡: {coverage:.2f}%")