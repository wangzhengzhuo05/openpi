"""
Pi0 CALVIN æ¨¡å‹è¯„ä¼°è„šæœ¬ - æœ€ç»ˆç‰ˆ v2
æ”¯æŒè¯­è¨€æŒ‡ä»¤åŠ è½½
æ”¯æŒç»Ÿè®¡å¼‚å¸¸
uv run evaluate_pi0_calvin.py \
    --checkpoint_dir /root/autodl-tmp/openpi/checkpoints/pi0_calvin_scratch/calvin_full/21000 \
    --dataset_path /root/autodl-tmp/huggingface/lerobot/Coil1987121/calvin_lerobot_task_ABCD_D_validation \
    --config_name pi0_calvin_scratch \
    --num_samples 100
"""

import sys
import json
import os
import io
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional

import numpy as np
import pandas as pd

# OpenPI è·¯å¾„é…ç½®
OPENPI_ROOT = os.environ.get('OPENPI_ROOT', '/root/autodl-tmp/openpi')
sys.path.insert(0, f'{OPENPI_ROOT}/src')
sys.path.insert(0, OPENPI_ROOT)


# ============================================================================
# å¼‚å¸¸æ•°æ®ç»Ÿè®¡
# ============================================================================

class AnomalyStats:
    """ç»Ÿè®¡å¼‚å¸¸æ•°æ®"""
    def __init__(self):
        self.reset()
    
    def reset(self):
        # å›¾åƒç›¸å…³
        self.base_image_failed = 0
        self.left_wrist_failed = 0
        self.right_wrist_failed = 0
        self.total_images_processed = 0
        
        # Prompt ç›¸å…³
        self.prompt_not_found = 0
        self.prompt_default_used = 0
        self.total_prompts_processed = 0
        
        # çŠ¶æ€ç›¸å…³
        self.state_failed = 0
        self.total_states_processed = 0
        
        # Action ç›¸å…³
        self.action_failed = 0
        self.total_actions_processed = 0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "images": {
                "base_image_failed": self.base_image_failed,
                "left_wrist_failed": self.left_wrist_failed,
                "right_wrist_failed": self.right_wrist_failed,
                "total_processed": self.total_images_processed,
                "failure_rate": (self.base_image_failed + self.left_wrist_failed + self.right_wrist_failed) / max(self.total_images_processed, 1),
            },
            "prompts": {
                "not_found": self.prompt_not_found,
                "default_used": self.prompt_default_used,
                "total_processed": self.total_prompts_processed,
                "failure_rate": self.prompt_not_found / max(self.total_prompts_processed, 1),
            },
            "states": {
                "failed": self.state_failed,
                "total_processed": self.total_states_processed,
                "failure_rate": self.state_failed / max(self.total_states_processed, 1),
            },
            "actions": {
                "failed": self.action_failed,
                "total_processed": self.total_actions_processed,
                "failure_rate": self.action_failed / max(self.total_actions_processed, 1),
            },
        }
    
    def print_summary(self):
        print("\n" + "=" * 50)
        print(" å¼‚å¸¸æ•°æ®ç»Ÿè®¡")
        print("=" * 50)
        
        total_img_failed = self.base_image_failed + self.left_wrist_failed + self.right_wrist_failed
        print(f"\nğŸ–¼ï¸  å›¾åƒå¼‚å¸¸:")
        print(f"  base_image åŠ è½½å¤±è´¥: {self.base_image_failed}")
        print(f"  left_wrist åŠ è½½å¤±è´¥: {self.left_wrist_failed}")
        print(f"  right_wrist åŠ è½½å¤±è´¥: {self.right_wrist_failed}")
        print(f"  æ€»å¤„ç†æ•°: {self.total_images_processed}")
        if self.total_images_processed > 0:
            print(f"  å¤±è´¥ç‡: {total_img_failed / self.total_images_processed * 100:.2f}%")
        
        print(f"\nğŸ“ Prompt å¼‚å¸¸:")
        print(f"  task_index æœªæ‰¾åˆ°: {self.prompt_not_found}")
        print(f"  ä½¿ç”¨é»˜è®¤ prompt: {self.prompt_default_used}")
        print(f"  æ€»å¤„ç†æ•°: {self.total_prompts_processed}")
        if self.total_prompts_processed > 0:
            print(f"  å¤±è´¥ç‡: {self.prompt_not_found / self.total_prompts_processed * 100:.2f}%")
        
        print(f"\nğŸ¤– State å¼‚å¸¸:")
        print(f"  è§£æå¤±è´¥: {self.state_failed}")
        print(f"  æ€»å¤„ç†æ•°: {self.total_states_processed}")
        if self.total_states_processed > 0:
            print(f"  å¤±è´¥ç‡: {self.state_failed / self.total_states_processed * 100:.2f}%")
        
        print(f"\nğŸ¯ Action å¼‚å¸¸:")
        print(f"  è§£æå¤±è´¥: {self.action_failed}")
        print(f"  æ€»å¤„ç†æ•°: {self.total_actions_processed}")
        if self.total_actions_processed > 0:
            print(f"  å¤±è´¥ç‡: {self.action_failed / self.total_actions_processed * 100:.2f}%")


# å…¨å±€å¼‚å¸¸ç»Ÿè®¡å¯¹è±¡
anomaly_stats = AnomalyStats()


# ============================================================================
# å›¾åƒè§£æ
# ============================================================================

def parse_image(image: Any, dataset_path: Path = None, image_type: str = "unknown") -> Tuple[np.ndarray, bool]:
    """
    è§£æå›¾åƒä¸º (H, W, C) uint8 æ ¼å¼
    
    Returns:
        image: è§£æåçš„å›¾åƒ
        success: æ˜¯å¦æˆåŠŸè§£æï¼ˆFalse è¡¨ç¤ºä½¿ç”¨äº†é›¶å¡«å……ï¼‰
    """
    from PIL import Image
    
    if image is None:
        return np.zeros((224, 224, 3), dtype=np.uint8), False
    
    # LeRobot å­—å…¸æ ¼å¼ {'bytes': b'...', 'path': '...'}
    if isinstance(image, dict):
        if 'bytes' in image and image['bytes'] is not None:
            try:
                pil_img = Image.open(io.BytesIO(image['bytes']))
                return np.array(pil_img.convert('RGB'), dtype=np.uint8), True
            except:
                pass
        return np.zeros((224, 224, 3), dtype=np.uint8), False
    
    # bytes æ•°æ®
    if isinstance(image, (bytes, bytearray)):
        try:
            pil_img = Image.open(io.BytesIO(image))
            return np.array(pil_img.convert('RGB'), dtype=np.uint8), True
        except:
            return np.zeros((224, 224, 3), dtype=np.uint8), False
    
    # numpy array
    try:
        image = np.asarray(image)
        if image.ndim == 3 and image.shape[0] in [1, 3, 4]:
            image = np.transpose(image, (1, 2, 0))
        if np.issubdtype(image.dtype, np.floating):
            image = (image * 255).clip(0, 255).astype(np.uint8)
        return image.astype(np.uint8), True
    except:
        return np.zeros((224, 224, 3), dtype=np.uint8), False


def parse_array(data: Any, expected_dim: int = 7) -> Tuple[np.ndarray, bool]:
    """
    è§£ææ•°ç»„
    
    Returns:
        array: è§£æåçš„æ•°ç»„
        success: æ˜¯å¦æˆåŠŸè§£æ
    """
    if data is None:
        return np.zeros(expected_dim, dtype=np.float32), False
    try:
        if isinstance(data, (list, tuple)):
            return np.array(data, dtype=np.float32).flatten(), True
        if isinstance(data, np.ndarray):
            return data.astype(np.float32).flatten(), True
    except:
        pass
    return np.zeros(expected_dim, dtype=np.float32), False


# ============================================================================
# è¯­è¨€æŒ‡ä»¤åŠ è½½
# ============================================================================

def load_task_instructions(dataset_path: Path) -> Dict[int, str]:
    """
    ä» meta/tasks.jsonl åŠ è½½ä»»åŠ¡æè¿°
    
    Returns:
        task_map: {task_index: task_description}
    """
    task_map = {}
    
    # å¯èƒ½çš„ä»»åŠ¡æ–‡ä»¶è·¯å¾„
    possible_paths = [
        dataset_path / "meta" / "tasks.jsonl",
        dataset_path / "tasks.jsonl",
        dataset_path / "meta" / "tasks.json",
    ]
    
    task_file = None
    for p in possible_paths:
        if p.exists():
            task_file = p
            break
    
    if task_file is None:
        print("âš  æœªæ‰¾åˆ°ä»»åŠ¡æè¿°æ–‡ä»¶ (tasks.jsonl)")
        return task_map
    
    print(f"åŠ è½½ä»»åŠ¡æè¿°: {task_file}")
    
    with open(task_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                item = json.loads(line)
                task_idx = item.get('task_index')
                task_desc = item.get('task', '')
                if task_idx is not None:
                    task_map[int(task_idx)] = task_desc
            except json.JSONDecodeError:
                continue
    
    print(f"  åŠ è½½äº† {len(task_map)} ä¸ªä»»åŠ¡æè¿°")
    
    # æ‰“å°å‡ ä¸ªç¤ºä¾‹
    if task_map:
        examples = list(task_map.items())[:3]
        for idx, desc in examples:
            print(f"  - [{idx}] {desc}")
    
    return task_map


# ============================================================================
# è¯„ä¼°æŒ‡æ ‡
# ============================================================================

def compute_rotation_error_np(q_pred, q_gt):
    """è®¡ç®—å››å…ƒæ•°è§’åº¦è¯¯å·® (åº¦)"""
    q_pred = q_pred / (np.linalg.norm(q_pred, axis=-1, keepdims=True) + 1e-8)
    q_gt = q_gt / (np.linalg.norm(q_gt, axis=-1, keepdims=True) + 1e-8)
    dot = np.abs(np.sum(q_pred * q_gt, axis=-1))
    dot = np.clip(dot, -1.0, 1.0)
    return np.rad2deg(2 * np.arccos(dot))


def evaluate_trajectory_np(pred_traj, gt_traj):
    """è¯„ä¼°è½¨è¿¹è´¨é‡ï¼ˆç»ˆç‚¹è¯¯å·® + å¤šæ¡£æˆåŠŸç‡ + éƒ¨åˆ†å…¨å±€ç»Ÿè®¡ï¼‰

    è¾“å…¥:
        pred_traj: [B, T, D] é¢„æµ‹è½¨è¿¹
        gt_traj:   [B, T, D] GT è½¨è¿¹
        çº¦å®šå‰3ç»´ä¸ºä½ç½® xyzï¼Œå4ç»´ä¸ºå››å…ƒæ•° qx, qy, qz, qw

    è¾“å‡º:
        metrics: dictï¼Œå…¼å®¹åŸç‰ˆ keyï¼ŒåŒæ—¶åŠ å…¥ä¸
                 evaluate_trajectory_quality ç­‰ä»·çš„ç»Ÿè®¡
    """
    metrics = {}

    # -------- 0. å®‰å…¨æ£€æŸ¥ --------
    pred_traj = np.asarray(pred_traj)
    gt_traj = np.asarray(gt_traj)
    assert pred_traj.shape == gt_traj.shape, \
        f"pred_traj shape {pred_traj.shape} != gt_traj shape {gt_traj.shape}"

    B, T, D = pred_traj.shape

    # ========== 1. ç»ˆç‚¹ä½ç½® / æ—‹è½¬è¯¯å·®ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼Œå¯¹é½åä¸€ä»½ä»£ç ï¼‰ ==========

    # ç»ˆç‚¹ä½ç½® [B, 3]
    pred_pos_final = pred_traj[:, -1, :3]
    gt_pos_final   = gt_traj[:, -1, :3]
    # ç»ˆç‚¹ä½ç½®è¯¯å·® (ç±³)
    pos_errors = np.linalg.norm(pred_pos_final - gt_pos_final, axis=-1)  # [B]

    # ç»ˆç‚¹æ—‹è½¬ [B, 4]
    if D >= 7:
        pred_rot_final = pred_traj[:, -1, 3:7]
        gt_rot_final   = gt_traj[:, -1, 3:7]
        # ç”¨ä½ åŸæ¥é‚£ä»½çš„ numpy ç‰ˆæœ¬æ—‹è½¬è¯¯å·®
        rot_errors = compute_rotation_error_np(pred_rot_final, gt_rot_final)  # [B]ï¼Œå•ä½: åº¦
        
        metrics['rot_error_mean_deg']   = float(rot_errors.mean())
        metrics['rot_error_median_deg'] = float(np.median(rot_errors))
        metrics['rot_error_std_deg']    = float(np.std(rot_errors))
        metrics["Mean_Rot_Error_deg"]  = float(rot_errors.mean())

    else:
        # æ²¡æœ‰æ—‹è½¬ç»´åº¦æ—¶ï¼Œæ—‹è½¬è¯¯å·®å…¨ 0ï¼Œé¿å…å´©
        rot_errors = np.zeros(B, dtype=np.float32)

    # ---- å¯¹é½ evaluate_trajectory_quality çš„æ ¸å¿ƒæŒ‡æ ‡ ----
    metrics["Mean_Pos_Error_cm"]   = float(pos_errors.mean() * 100.0)
    metrics["Mean_Rot_Error_deg"]  = float(rot_errors.mean())

    # å®½æ¾æ ‡å‡† (5cm, 10Â°)
    sr_loose = np.mean((pos_errors < 0.05) & (rot_errors < 10.0))
    # ä¸¥æ ¼æ ‡å‡† (2cm, 5Â°)
    sr_strict = np.mean((pos_errors < 0.02) & (rot_errors < 5.0))
    # é«˜ç²¾åº¦ (1cm, 2Â°)
    sr_highprec = np.mean((pos_errors < 0.01) & (rot_errors < 2.0))

    metrics["SR_Loose"]    = float(sr_loose)
    metrics["SR_Strict"]   = float(sr_strict)
    metrics["SR_HighPrec"] = float(sr_highprec)

    # åŒæ—¶å…¼å®¹ä½ åŸæ¥ç”¨çš„å‘½åï¼ˆæ–¹ä¾¿è€è„šæœ¬ä¸ç‚¸ï¼‰
    metrics["sr_5cm_10deg"] = float(sr_loose)
    metrics["sr_2cm_5deg"]  = float(sr_strict)
    metrics["sr_1cm_2deg"]  = float(sr_highprec)

    # ========== 2. ä¿ç•™éƒ¨åˆ†å…¨è½¨è¿¹/ä½ç½®ç»Ÿè®¡ï¼ˆåŸå‡½æ•°æœ‰çš„ï¼‰ ==========

    # å…¨è½¨è¿¹åŸºç¡€è¯¯å·®ï¼ˆæŒ‰ä½ åŸæ¥çš„å®šä¹‰ï¼‰
    metrics['traj_mse'] = float(np.mean((pred_traj - gt_traj) ** 2))
    metrics['traj_mae'] = float(np.mean(np.abs(pred_traj - gt_traj)))
    metrics['traj_rmse'] = float(np.sqrt(metrics['traj_mse']))

    # ä½ç½®è¯¯å·®ï¼ˆå…¨è½¨è¿¹ä¸Šï¼‰
    pos_pred_all, pos_gt_all = pred_traj[:, :, :3], gt_traj[:, :, :3]
    metrics['pos_mse'] = float(np.mean((pos_pred_all - pos_gt_all) ** 2))
    metrics['pos_rmse_cm'] = float(np.sqrt(metrics['pos_mse']) * 100.0)

    # FDE / ADEï¼ˆä¸åä¸€ä»½æ•ˆæœä¸€è‡´ï¼šFDE/ADE ç”¨ç»ˆç‚¹/å…¨è½¨è¿¹è·ç¦»ï¼‰
    fde = pos_errors  # ç»ˆç‚¹è¯¯å·®æœ¬èº«å°±æ˜¯ FDEï¼ˆå•ä½ï¼šç±³ï¼‰
    metrics['fde_mean_cm']    = float(np.mean(fde) * 100.0)
    metrics['fde_median_cm']  = float(np.median(fde) * 100.0)
    metrics['fde_std_cm']     = float(np.std(fde) * 100.0)

    ade = np.mean(
        np.linalg.norm(pos_pred_all - pos_gt_all, axis=-1), axis=1
    )  # [B]ï¼Œå…¨è½¨è¿¹å¹³å‡è·ç¦»
    metrics['ade_mean_cm']    = float(np.mean(ade) * 100.0)
    metrics['ade_median_cm']  = float(np.median(ade) * 100.0)

    # ========== 3. ä¿ç•™æ—‹è½¬ MSE / per-dim MSEï¼ˆå¦‚æœæœ‰æ—‹è½¬ç»´åº¦ï¼‰ ==========

    if D >= 7:
        # å…¨è½¨è¿¹ä¸Š 3:7 ç»´çš„ MSE
        metrics['rot_mse'] = float(np.mean((pred_traj[:, :, 3:7] - gt_traj[:, :, 3:7]) ** 2))

    # æ¯ç»´åº¦ MSEï¼ˆå…¨è½¨è¿¹ + å…¨ batchï¼‰
    per_dim_mse = np.mean((pred_traj - gt_traj) ** 2, axis=(0, 1))
    dim_names = ['x', 'y', 'z', 'qx', 'qy', 'qz', 'qw', 'gripper'][:D]
    for i, name in enumerate(dim_names):
        metrics[f'mse_{name}'] = float(per_dim_mse[i])

    return metrics



# ============================================================================
# æ•°æ®é›†ç±»
# ============================================================================

def find_column(df, patterns):
    for pattern in patterns:
        if pattern in df.columns:
            return pattern
        for col in df.columns:
            if pattern.lower() in col.lower():
                return col
    return None


class CALVINEvalDataset:
    """CALVIN è¯„ä¼°æ•°æ®é›†"""
    
    def __init__(
        self, 
        dataset_path: str, 
        max_episodes: int = None, 
        verbose: bool = True
    ):
        self.dataset_path = Path(dataset_path)
        self.verbose = verbose
        
        # åŠ è½½ä»»åŠ¡æè¿°
        self.task_map = load_task_instructions(self.dataset_path)
        
        # åŠ è½½æ•°æ®
        self.data = self._load_data()
        self._detect_columns()
        self.episodes = self._build_episodes(max_episodes)
        
        if verbose:
            print(f"âœ“ æ•°æ®é›†: {len(self.episodes)} episodes, {len(self.data)} frames")
    
    def _load_data(self):
        for data_dir in [self.dataset_path / "data", self.dataset_path]:
            if not data_dir.exists():
                continue
            parquet_files = list(data_dir.rglob("*.parquet"))
            if parquet_files:
                if self.verbose:
                    print(f"ä» {data_dir} åŠ è½½ {len(parquet_files)} ä¸ª parquet æ–‡ä»¶...")
                dfs = [pd.read_parquet(f) for f in tqdm(parquet_files, desc="è¯»å–æ•°æ®", disable=not self.verbose)]
                return pd.concat(dfs, ignore_index=True)
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ•°æ®: {self.dataset_path}")
    
    def _detect_columns(self):
        # CALVIN ç‰¹å®šçš„åˆ—å
        self.base_image_col = find_column(self.data, [
            'observation.images.base_0_rgb', 
            'observation.images.rgb_static',
            'rgb_static'
        ])
        self.left_wrist_col = find_column(self.data, [
            'observation.images.left_wrist_0_rgb',
            'observation.images.rgb_gripper',
            'rgb_gripper'
        ])
        self.right_wrist_col = find_column(self.data, [
            'observation.images.right_wrist_0_rgb'
        ])
        self.state_col = find_column(self.data, [
            'observation.state', 
            'robot_obs', 
            'state'
        ])
        self.action_col = find_column(self.data, [
            'actions', 
            'action', 
            'rel_actions'
        ])
        self.episode_col = find_column(self.data, [
            'episode_index', 
            'episode'
        ])
        # ä»»åŠ¡ç´¢å¼•åˆ—
        self.task_index_col = find_column(self.data, [
            'task_index',
            'task_idx',
        ])
        if self.action_col is None:
            raise RuntimeError("æ•°æ®é›†ä¸­æœªæ‰¾åˆ°åŠ¨ä½œåˆ— (actions / action / rel_actions)")
        
        if self.verbose:
            print(f"\næ£€æµ‹åˆ°çš„åˆ—:")
            print(f"  base_image: {self.base_image_col}")
            print(f"  left_wrist: {self.left_wrist_col}")
            print(f"  right_wrist: {self.right_wrist_col}")
            print(f"  state: {self.state_col}")
            print(f"  action: {self.action_col}")
            print(f"  episode: {self.episode_col}")
            print(f"  task_index: {self.task_index_col}")
    
    def _build_episodes(self, max_episodes):
        if not self.episode_col or self.episode_col not in self.data.columns:
            return [{'episode_index': 0, 'start': 0, 'end': len(self.data) - 1}]
        
        episodes = []
        unique_eps = sorted(self.data[self.episode_col].unique())
        if max_episodes:
            unique_eps = unique_eps[:max_episodes]
        
        for ep_idx in unique_eps:
            indices = self.data.index[self.data[self.episode_col] == ep_idx]
            episodes.append({
                'episode_index': ep_idx, 
                'start': indices.min(), 
                'end': indices.max()
            })
        return episodes
    
    def get_task_description(self, task_index: Any) -> Tuple[str, bool]:
        """
        æ ¹æ® task_index è·å–ä»»åŠ¡æè¿°
        
        Returns:
            description: ä»»åŠ¡æè¿°
            success: æ˜¯å¦æˆåŠŸè·å–ï¼ˆFalse è¡¨ç¤ºä½¿ç”¨äº†é»˜è®¤å€¼æˆ–æœªæ‰¾åˆ°ï¼‰
        """
        if task_index is None:
            return "perform the task", False
        
        try:
            idx = int(task_index)
            if idx in self.task_map:
                return self.task_map[idx], True
            else:
                return f"perform task {idx}", False
        except (ValueError, TypeError):
            return "perform the task", False
    
    def get_sample(self, idx: int) -> Dict[str, Any]:
        """
        è·å–å•ä¸ªæ ·æœ¬ï¼Œæ ¼å¼åŒ–ä¸º CALVIN policy æœŸæœ›çš„è¾“å…¥
        åŒæ—¶ç»Ÿè®¡å¼‚å¸¸æ•°æ®
        """
        global anomaly_stats
        row = self.data.iloc[idx]
        
        # æ„å»º images å­—å…¸
        images = {}
        
        # Base image
        anomaly_stats.total_images_processed += 1
        if self.base_image_col:
            img, success = parse_image(row[self.base_image_col], self.dataset_path, "base")
            images["base_0_rgb"] = img
            if not success:
                anomaly_stats.base_image_failed += 1
        else:
            images["base_0_rgb"] = np.zeros((224, 224, 3), dtype=np.uint8)
            anomaly_stats.base_image_failed += 1
        
        # Left wrist image
        anomaly_stats.total_images_processed += 1
        if self.left_wrist_col:
            img, success = parse_image(row[self.left_wrist_col], self.dataset_path, "left_wrist")
            images["left_wrist_0_rgb"] = img
            if not success:
                anomaly_stats.left_wrist_failed += 1
        else:
            images["left_wrist_0_rgb"] = np.zeros((224, 224, 3), dtype=np.uint8)
            anomaly_stats.left_wrist_failed += 1
        
        # Right wrist image
        anomaly_stats.total_images_processed += 1
        if self.right_wrist_col:
            img, success = parse_image(row[self.right_wrist_col], self.dataset_path, "right_wrist")
            images["right_wrist_0_rgb"] = img
            if not success:
                anomaly_stats.right_wrist_failed += 1
        else:
            images["right_wrist_0_rgb"] = np.zeros((224, 224, 3), dtype=np.uint8)
            anomaly_stats.right_wrist_failed += 1
        
        # çŠ¶æ€
        anomaly_stats.total_states_processed += 1
        if self.state_col:
            state, success = parse_array(row[self.state_col], 32)
            if not success:
                anomaly_stats.state_failed += 1
        else:
            state = np.zeros(8, dtype=np.float32)
            anomaly_stats.state_failed += 1
        
        # ä»»åŠ¡æç¤º - ä» task_index è·å–è¯­è¨€æŒ‡ä»¤
        anomaly_stats.total_prompts_processed += 1
        prompt = "perform the task"
        prompt_success = False
        if self.task_index_col and self.task_index_col in self.data.columns:
            task_idx = row[self.task_index_col]
            prompt, prompt_success = self.get_task_description(task_idx)
        
        if not prompt_success:
            anomaly_stats.prompt_not_found += 1
        if prompt == "perform the task":
            anomaly_stats.prompt_default_used += 1
        
        # æ„å»ºè¿”å›å­—å…¸
        sample = {
            "images": images,
            "state": state,
            "prompt": prompt,
        }
        
        # ä¿å­˜ GT action ç”¨äºè¯„ä¼°
        if self.action_col:
            action, success = parse_array(row[self.action_col], 7)
            sample["gt_action"] = action
            anomaly_stats.total_actions_processed += 1
            if not success:
                anomaly_stats.action_failed += 1
        
        # ä¿å­˜ task_index ç”¨äºåˆ†æ
        if self.task_index_col and self.task_index_col in self.data.columns:
            sample["task_index"] = row[self.task_index_col]
        
        return sample
    
    def get_evaluation_samples(
        self, 
        action_horizon: int = 10, 
        num_samples: int = None,
        skip_interval: int = 1
    ) -> Tuple[List[Dict], np.ndarray]:
        """è·å–è¯„ä¼°æ ·æœ¬"""
        global anomaly_stats
        samples = []
        gt_trajectories = []
        
        for ep in tqdm(self.episodes, desc="æå–æ ·æœ¬", disable=not self.verbose):
            for start_idx in range(ep['start'], ep['end'] - action_horizon + 1, skip_interval):
                if start_idx + action_horizon > ep['end']:
                    break
                
                # è·å–è¾“å…¥æ ·æœ¬
                sample = self.get_sample(start_idx)
                
                # GT è½¨è¿¹
                gt_actions = []
                for i in range(action_horizon):
                    action = self.data.iloc[start_idx + i][self.action_col]
                    action_arr, success = parse_array(action, 7)
                    gt_actions.append(action_arr)
                    # GT action ç»Ÿè®¡å·²ç»åœ¨ get_sample ä¸­å¤„ç†äº†ç¬¬ä¸€ä¸ª
                    # è¿™é‡Œåªç»Ÿè®¡åç»­çš„ action_horizon - 1 ä¸ª
                    if i > 0:
                        anomaly_stats.total_actions_processed += 1
                        if not success:
                            anomaly_stats.action_failed += 1
                
                samples.append(sample)
                gt_trajectories.append(np.stack(gt_actions))
                
                if num_samples and len(samples) >= num_samples:
                    break
            
            if num_samples and len(samples) >= num_samples:
                break
        
        return samples, np.stack(gt_trajectories)


# ============================================================================
# æ¨ç†å‡½æ•°
# ============================================================================

def run_inference(
    policy,
    samples: List[Dict],
    action_horizon: int,
    action_dim: int = 7,
    show_progress: bool = True
) -> Tuple[np.ndarray, int]:
    """è¿è¡Œæ¨¡å‹æ¨ç†"""
    predictions = []
    num_errors = 0
    
    iterator = tqdm(samples, desc="æ¨ç†") if show_progress else samples
    
    for sample in iterator:
        try:
            # è¾“å…¥æ ¼å¼: {"images": {...}, "state": ..., "prompt": ...}
            input_dict = {
                "images": sample["images"],
                "state": sample["state"],
                "prompt": sample["prompt"],
            }
            
            # è°ƒç”¨æ¨ç†
            result = policy.infer(input_dict)
            actions = np.array(result['actions'])
            
            # è°ƒæ•´é•¿åº¦
            if len(actions) >= action_horizon:
                actions = actions[:action_horizon]
            else:
                pad_len = action_horizon - len(actions)
                actions = np.concatenate([actions, np.tile(actions[-1:], (pad_len, 1))])
            
            # è°ƒæ•´ç»´åº¦
            if actions.shape[-1] < action_dim:
                pad = np.zeros((action_horizon, action_dim - actions.shape[-1]))
                actions = np.concatenate([actions, pad], axis=-1)
            else:
                actions = actions[..., :action_dim]
            
            predictions.append(actions)
            
        except Exception as e:
            num_errors += 1
            if num_errors <= 3:
                print(f"\næ¨ç†é”™è¯¯: {e}")
            predictions.append(np.zeros((action_horizon, action_dim), dtype=np.float32))
    
    return np.stack(predictions), num_errors


# ============================================================================
# ä¸»è¯„ä¼°å‡½æ•°
# ============================================================================

def run_evaluation(
    checkpoint_dir: str,
    dataset_path: str,
    config_name: str = "pi0_calvin_scratch",
    num_samples: int = 100,
    action_horizon: int = 10,
    skip_interval: int = 10,
    output_dir: str = None,
    output_filename: str = None,
    verbose: bool = True,
):
    """è¿è¡Œå®Œæ•´è¯„ä¼°"""
    global anomaly_stats
    
    from openpi.training import config as _config
    from openpi.policies import policy_config as _policy_config
    
    # é‡ç½®å¼‚å¸¸ç»Ÿè®¡
    anomaly_stats.reset()
    
    if verbose:
        print("\n" + "=" * 70)
        print(" Pi0 CALVIN çœŸå®æ¨ç†è¯„ä¼° (æ”¯æŒè¯­è¨€æŒ‡ä»¤)")
        print("=" * 70)
    
    # 1. åŠ è½½ç­–ç•¥
    if verbose:
        print("\nã€1ã€‘åŠ è½½ç­–ç•¥...")
    
    config = _config.get_config(config_name)
    
    if verbose:
        print(f"é…ç½®: {config_name}")
        print(f"  action_dim: {config.model.action_dim}")
        print(f"  action_horizon: {config.model.action_horizon}")
    
    try:
        policy = _policy_config.create_trained_policy(config, checkpoint_dir)
        if verbose:
            print("âœ“ ç­–ç•¥åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç­–ç•¥åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # 2. åŠ è½½æ•°æ®é›†
    if verbose:
        print("\nã€2ã€‘åŠ è½½æ•°æ®é›†...")
    
    dataset = CALVINEvalDataset(
        dataset_path, 
        max_episodes=num_samples * 2,
        verbose=verbose
    )
    
    # 3. æå–æ ·æœ¬
    if verbose:
        print("\nã€3ã€‘æå–è¯„ä¼°æ ·æœ¬...")
    
    samples, gt_trajectories = dataset.get_evaluation_samples(
        action_horizon=action_horizon,
        num_samples=num_samples,
        skip_interval=skip_interval
    )
    
    if verbose:
        print(f"è¯„ä¼°æ ·æœ¬æ•°: {len(samples)}")
        print(f"GT è½¨è¿¹å½¢çŠ¶: {gt_trajectories.shape}")
        
        # æ‰“å°ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼
        s = samples[0]
        print(f"\næ ·æœ¬æ ¼å¼:")
        print(f"  images.base_0_rgb: {s['images']['base_0_rgb'].shape}, {s['images']['base_0_rgb'].dtype}")
        print(f"  images.left_wrist_0_rgb: {s['images']['left_wrist_0_rgb'].shape}")
        print(f"  state: {s['state'].shape}, {s['state'].dtype}")
        print(f"  prompt: \"{s['prompt']}\"")
        
        # ç»Ÿè®¡ä»»åŠ¡åˆ†å¸ƒ
        if 'task_index' in samples[0]:
            task_counts = {}
            for samp in samples:
                t = samp.get('task_index', -1)
                task_counts[t] = task_counts.get(t, 0) + 1
            print(f"\nä»»åŠ¡åˆ†å¸ƒ (å‰5ä¸ª):")
            for t, c in sorted(task_counts.items(), key=lambda x: -x[1])[:5]:
                desc, _ = dataset.get_task_description(t)
                print(f"  [{t}] {desc}: {c} æ ·æœ¬")
    
    # 4. æ¨ç†
    if verbose:
        print("\nã€4ã€‘è¿è¡Œæ¨¡å‹æ¨ç†...")
    
    action_dim = gt_trajectories.shape[-1]
    pred_trajectories, num_errors = run_inference(
        policy=policy,
        samples=samples,
        action_horizon=action_horizon,
        action_dim=action_dim,
        show_progress=verbose
    )
    
    if verbose:
        print(f"\né¢„æµ‹è½¨è¿¹å½¢çŠ¶: {pred_trajectories.shape}")
        if num_errors > 0:
            print(f"âš  {num_errors} ä¸ªæ ·æœ¬æ¨ç†å‡ºé”™")
        else:
            print("âœ“ æ‰€æœ‰æ ·æœ¬æ¨ç†æˆåŠŸ")
    
    # 5. è®¡ç®—æŒ‡æ ‡
    if verbose:
        print("\nã€5ã€‘è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    
    min_dim = min(pred_trajectories.shape[-1], gt_trajectories.shape[-1])
    metrics = evaluate_trajectory_np(
        pred_trajectories[..., :min_dim], 
        gt_trajectories[..., :min_dim]
    )
    
    # 6. æ‰“å°ç»“æœ
    if verbose:
        print("\n" + "=" * 70)
        print(" è¯„ä¼°ç»“æœ")
        print("=" * 70)
        
        print("\nğŸ“Š è½¨è¿¹è¯¯å·®:")
        print(f"  MSE:  {metrics['traj_mse']:.6f}")
        print(f"  MAE:  {metrics['traj_mae']:.6f}")
        print(f"  RMSE: {metrics['traj_rmse']:.6f}")
        
        print("\nğŸ“ ä½ç½®è¯¯å·®:")
        print(f"  Position MSE:  {metrics['pos_mse']:.6f}")
        print(f"  Position RMSE: {metrics['pos_rmse_cm']:.2f} cm")
        print(f"  ADE: {metrics['ade_mean_cm']:.2f} cm (median: {metrics['ade_median_cm']:.2f})")
        print(f"  FDE: {metrics['fde_mean_cm']:.2f} cm (median: {metrics['fde_median_cm']:.2f})")
        
        if 'rot_error_mean_deg' in metrics:
            print("\nğŸ”„ æ—‹è½¬è¯¯å·®:")
            print(f"  Mean:   {metrics['rot_error_mean_deg']:.2f}Â°")
            print(f"  Median: {metrics['rot_error_median_deg']:.2f}Â°")
            print(f"  Std:    {metrics['rot_error_std_deg']:.2f}Â°")
            
        print("\nâœ… æˆåŠŸç‡:")
        print(f"  SR (1cm, 2Â°):  {metrics['sr_1cm_2deg']*100:.2f}%")
        print(f"  SR (2cm, 5Â°):  {metrics['sr_2cm_5deg']*100:.2f}%  â† æ¨èæŒ‡æ ‡")
        print(f"  SR (5cm, 10Â°): {metrics['sr_5cm_10deg']*100:.2f}%")
        #print(f"  SR (5cm, 15Â°): {metrics['sr_5cm_15deg']*100:.2f}%")
        
        print("\nğŸ“ å„ç»´åº¦ MSE:")
        for key in sorted([k for k in metrics.keys() if k.startswith('mse_')]):
            dim = key.replace('mse_', '')
            print(f"  {dim}: {metrics[key]:.6f}")
        
        # æ‰“å°å¼‚å¸¸æ•°æ®ç»Ÿè®¡
        anomaly_stats.print_summary()
    
    # 7. ä¿å­˜ç»“æœ
    if output_dir is None:
        output_dir = Path(OPENPI_ROOT) / 'evaluation' / 'results'
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if output_filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        try:
            checkpoint_name = Path(checkpoint_dir).parts[-2]
            step = Path(checkpoint_dir).name
        except:
            checkpoint_name = "model"
            step = "0"
        output_filename = f"eval_{checkpoint_name}_{step}_{timestamp}.json"
    
    result = {
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "checkpoint_dir": str(checkpoint_dir),
            "dataset_path": str(dataset_path),
            "config_name": config_name,
            "num_samples": len(samples),
            "num_errors": num_errors,
            "action_horizon": action_horizon,
            "inference_mode": "real",
            "has_language_instructions": bool(dataset.task_map),
        },
        "metrics": metrics,
        "summary": {
            "trajectory_mse": metrics.get('traj_mse'),
            "position_mse": metrics.get('pos_mse'),
            "fde_cm": metrics.get('fde_mean_cm'),
            "ade_cm": metrics.get('ade_mean_cm'),
            "rotation_error_deg": metrics.get('rot_error_mean_deg'),
            "success_rate_2cm_5deg": metrics.get('sr_2cm_5deg'),
        },
        "anomaly_stats": anomaly_stats.to_dict(),
    }
    
    output_path = output_dir / output_filename
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    if verbose:
        print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    # åˆ›å»ºæœ€æ–°ç»“æœé“¾æ¥
    latest_path = output_dir / "latest_eval.json"
    try:
        if latest_path.exists() or latest_path.is_symlink():
            latest_path.unlink()
        latest_path.symlink_to(output_path.name)
    except:
        import shutil
        shutil.copy(output_path, latest_path)
    
    if verbose:
        print("=" * 70)
    
    return metrics


# ============================================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================================

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Pi0 CALVIN è¯„ä¼° (æ”¯æŒè¯­è¨€æŒ‡ä»¤)')
    parser.add_argument('--checkpoint_dir', type=str, required=True,
                        help='æ£€æŸ¥ç‚¹ç›®å½•')
    parser.add_argument('--dataset_path', type=str, required=True,
                        help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--config_name', type=str, default='pi0_calvin_scratch',
                        help='é…ç½®åç§°')
    parser.add_argument('--num_samples', type=int, default=100,
                        help='è¯„ä¼°æ ·æœ¬æ•°')
    parser.add_argument('--action_horizon', type=int, default=10,
                        help='åŠ¨ä½œåºåˆ—é•¿åº¦')
    parser.add_argument('--skip_interval', type=int, default=10,
                        help='é‡‡æ ·é—´éš”')
    parser.add_argument('--output_dir', type=str, default=None,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--output_filename', type=str, default=None,
                        help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--quiet', action='store_true',
                        help='å‡å°‘è¾“å‡º')
    
    args = parser.parse_args()
    
    run_evaluation(
        checkpoint_dir=args.checkpoint_dir,
        dataset_path=args.dataset_path,
        config_name=args.config_name,
        num_samples=args.num_samples,
        action_horizon=args.action_horizon,
        skip_interval=args.skip_interval,
        output_dir=args.output_dir,
        output_filename=args.output_filename,
        verbose=not args.quiet,
    )