"""
Pi0 CALVIN æ¨¡å‹è¯„ä¼°è„šæœ¬ - æœ€ç»ˆç‰ˆ v2
æ”¯æŒè¯­è¨€æŒ‡ä»¤åŠ è½½

uv run /path/to/evaluate_pi0_calvin.py \
    --checkpoint_dir /root/autodl-tmp/openpi/checkpoints/pi0_calvin_scratch/calvin_full/21000 \
    --dataset_path /root/autodl-tmp/huggingface/lerobot/Coil1987121/calvin_lerobot_task_ABCD_D_validation \
    --config_name pi0_calvin_scratch \
    --num_samples 100 \
    --action_horizon 10
"""

import sys
import json
import os
import io
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional

import numpy as np
import pandas as pd

# OpenPI è·¯å¾„é…ç½®
OPENPI_ROOT = os.environ.get('OPENPI_ROOT', '/root/autodl-tmp/openpi')
sys.path.insert(0, f'{OPENPI_ROOT}/src')
sys.path.insert(0, OPENPI_ROOT)


# ============================================================================
# å›¾åƒè§£æ
# ============================================================================

def parse_image(image: Any, dataset_path: Path = None) -> np.ndarray:
    """è§£æå›¾åƒä¸º (H, W, C) uint8 æ ¼å¼"""
    from PIL import Image
    
    if image is None:
        return np.zeros((224, 224, 3), dtype=np.uint8)
    
    # LeRobot å­—å…¸æ ¼å¼ {'bytes': b'...', 'path': '...'}
    if isinstance(image, dict):
        if 'bytes' in image and image['bytes'] is not None:
            try:
                pil_img = Image.open(io.BytesIO(image['bytes']))
                return np.array(pil_img.convert('RGB'), dtype=np.uint8)
            except:
                pass
        return np.zeros((224, 224, 3), dtype=np.uint8)
    
    # bytes æ•°æ®
    if isinstance(image, (bytes, bytearray)):
        try:
            pil_img = Image.open(io.BytesIO(image))
            return np.array(pil_img.convert('RGB'), dtype=np.uint8)
        except:
            return np.zeros((224, 224, 3), dtype=np.uint8)
    
    # numpy array
    image = np.asarray(image)
    if image.ndim == 3 and image.shape[0] in [1, 3, 4]:
        image = np.transpose(image, (1, 2, 0))
    if np.issubdtype(image.dtype, np.floating):
        image = (image * 255).clip(0, 255).astype(np.uint8)
    return image.astype(np.uint8)


def parse_array(data: Any, expected_dim: int = 7) -> np.ndarray:
    """è§£ææ•°ç»„"""
    if data is None:
        return np.zeros(expected_dim, dtype=np.float32)
    if isinstance(data, (list, tuple)):
        return np.array(data, dtype=np.float32).flatten()
    if isinstance(data, np.ndarray):
        return data.astype(np.float32).flatten()
    return np.zeros(expected_dim, dtype=np.float32)


# ============================================================================
# è¯­è¨€æŒ‡ä»¤åŠ è½½
# ============================================================================

def load_task_instructions(dataset_path: Path) -> Dict[int, str]:
    """
    ä» meta/tasks.jsonl åŠ è½½ä»»åŠ¡æè¿°
    
    Returns:
        task_map: {task_index: task_description}
    """
    task_map = {}
    
    # å¯èƒ½çš„ä»»åŠ¡æ–‡ä»¶è·¯å¾„
    possible_paths = [
        dataset_path / "meta" / "tasks.jsonl",
        dataset_path / "tasks.jsonl",
        dataset_path / "meta" / "tasks.json",
    ]
    
    task_file = None
    for p in possible_paths:
        if p.exists():
            task_file = p
            break
    
    if task_file is None:
        print("âš  æœªæ‰¾åˆ°ä»»åŠ¡æè¿°æ–‡ä»¶ (tasks.jsonl)")
        return task_map
    
    print(f"åŠ è½½ä»»åŠ¡æè¿°: {task_file}")
    
    with open(task_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                item = json.loads(line)
                task_idx = item.get('task_index')
                task_desc = item.get('task', '')
                if task_idx is not None:
                    task_map[int(task_idx)] = task_desc
            except json.JSONDecodeError:
                continue
    
    print(f"  åŠ è½½äº† {len(task_map)} ä¸ªä»»åŠ¡æè¿°")
    
    # æ‰“å°å‡ ä¸ªç¤ºä¾‹
    if task_map:
        examples = list(task_map.items())[:3]
        for idx, desc in examples:
            print(f"  - [{idx}] {desc}")
    
    return task_map


# ============================================================================
# è¯„ä¼°æŒ‡æ ‡
# ============================================================================

def compute_rotation_error_np(q_pred, q_gt):
    """è®¡ç®—å››å…ƒæ•°è§’åº¦è¯¯å·® (åº¦)"""
    q_pred = q_pred / (np.linalg.norm(q_pred, axis=-1, keepdims=True) + 1e-8)
    q_gt = q_gt / (np.linalg.norm(q_gt, axis=-1, keepdims=True) + 1e-8)
    dot = np.abs(np.sum(q_pred * q_gt, axis=-1))
    dot = np.clip(dot, -1.0, 1.0)
    return np.rad2deg(2 * np.arccos(dot))


def evaluate_trajectory_np(pred_traj, gt_traj):
    """è¯„ä¼°è½¨è¿¹è´¨é‡"""
    metrics = {}
    
    # åŸºç¡€è¯¯å·®
    metrics['traj_mse'] = float(np.mean((pred_traj - gt_traj) ** 2))
    metrics['traj_mae'] = float(np.mean(np.abs(pred_traj - gt_traj)))
    metrics['traj_rmse'] = float(np.sqrt(metrics['traj_mse']))
    
    # ä½ç½®è¯¯å·®
    pos_pred, pos_gt = pred_traj[:, :, :3], gt_traj[:, :, :3]
    metrics['pos_mse'] = float(np.mean((pos_pred - pos_gt) ** 2))
    metrics['pos_rmse_cm'] = float(np.sqrt(metrics['pos_mse']) * 100)
    
    # FDE / ADE
    fde = np.linalg.norm(pos_pred[:, -1] - pos_gt[:, -1], axis=-1)
    metrics['fde_mean_cm'] = float(np.mean(fde) * 100)
    metrics['fde_median_cm'] = float(np.median(fde) * 100)
    metrics['fde_std_cm'] = float(np.std(fde) * 100)
    
    ade = np.mean(np.linalg.norm(pos_pred - pos_gt, axis=-1), axis=1)
    metrics['ade_mean_cm'] = float(np.mean(ade) * 100)
    metrics['ade_median_cm'] = float(np.median(ade) * 100)
    
    # æ—‹è½¬è¯¯å·®
    if pred_traj.shape[-1] >= 7:
        rot_err = compute_rotation_error_np(pred_traj[:, -1, 3:7], gt_traj[:, -1, 3:7])
        metrics['rot_error_mean_deg'] = float(np.mean(rot_err))
        metrics['rot_error_median_deg'] = float(np.median(rot_err))
        metrics['rot_error_std_deg'] = float(np.std(rot_err))
        metrics['rot_mse'] = float(np.mean((pred_traj[:, :, 3:7] - gt_traj[:, :, 3:7]) ** 2))
        
        # æˆåŠŸç‡
        metrics['sr_1cm_2deg'] = float(np.mean((fde < 0.01) & (rot_err < 2.0)))
        metrics['sr_2cm_5deg'] = float(np.mean((fde < 0.02) & (rot_err < 5.0)))
        metrics['sr_3cm_10deg'] = float(np.mean((fde < 0.03) & (rot_err < 10.0)))
        metrics['sr_5cm_15deg'] = float(np.mean((fde < 0.05) & (rot_err < 15.0)))
    
    # æ¯ç»´åº¦ MSE
    per_dim_mse = np.mean((pred_traj - gt_traj) ** 2, axis=(0, 1))
    dim_names = ['x', 'y', 'z', 'qx', 'qy', 'qz', 'qw', 'gripper'][:pred_traj.shape[-1]]
    for i, name in enumerate(dim_names):
        metrics[f'mse_{name}'] = float(per_dim_mse[i])
    
    return metrics


# ============================================================================
# æ•°æ®é›†ç±»
# ============================================================================

def find_column(df, patterns):
    for pattern in patterns:
        if pattern in df.columns:
            return pattern
        for col in df.columns:
            if pattern.lower() in col.lower():
                return col
    return None


class CALVINEvalDataset:
    """CALVIN è¯„ä¼°æ•°æ®é›†"""
    
    def __init__(
        self, 
        dataset_path: str, 
        max_episodes: int = None, 
        verbose: bool = True
    ):
        self.dataset_path = Path(dataset_path)
        self.verbose = verbose
        
        # åŠ è½½ä»»åŠ¡æè¿°
        self.task_map = load_task_instructions(self.dataset_path)
        
        # åŠ è½½æ•°æ®
        self.data = self._load_data()
        self._detect_columns()
        self.episodes = self._build_episodes(max_episodes)
        
        if verbose:
            print(f"âœ“ æ•°æ®é›†: {len(self.episodes)} episodes, {len(self.data)} frames")
    
    def _load_data(self):
        for data_dir in [self.dataset_path / "data", self.dataset_path]:
            if not data_dir.exists():
                continue
            parquet_files = list(data_dir.rglob("*.parquet"))
            if parquet_files:
                if self.verbose:
                    print(f"ä» {data_dir} åŠ è½½ {len(parquet_files)} ä¸ª parquet æ–‡ä»¶...")
                dfs = [pd.read_parquet(f) for f in tqdm(parquet_files, desc="è¯»å–æ•°æ®", disable=not self.verbose)]
                return pd.concat(dfs, ignore_index=True)
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ•°æ®: {self.dataset_path}")
    
    def _detect_columns(self):
        # CALVIN ç‰¹å®šçš„åˆ—å
        self.base_image_col = find_column(self.data, [
            'observation.images.base_0_rgb', 
            'observation.images.rgb_static',
            'rgb_static'
        ])
        self.left_wrist_col = find_column(self.data, [
            'observation.images.left_wrist_0_rgb',
            'observation.images.rgb_gripper',
            'rgb_gripper'
        ])
        self.right_wrist_col = find_column(self.data, [
            'observation.images.right_wrist_0_rgb'
        ])
        self.state_col = find_column(self.data, [
            'observation.state', 
            'robot_obs', 
            'state'
        ])
        self.action_col = find_column(self.data, [
            'actions', 
            'action', 
            'rel_actions'
        ])
        self.episode_col = find_column(self.data, [
            'episode_index', 
            'episode'
        ])
        # ä»»åŠ¡ç´¢å¼•åˆ—
        self.task_index_col = find_column(self.data, [
            'task_index',
            'task_idx',
        ])
        
        if self.verbose:
            print(f"\næ£€æµ‹åˆ°çš„åˆ—:")
            print(f"  base_image: {self.base_image_col}")
            print(f"  left_wrist: {self.left_wrist_col}")
            print(f"  right_wrist: {self.right_wrist_col}")
            print(f"  state: {self.state_col}")
            print(f"  action: {self.action_col}")
            print(f"  episode: {self.episode_col}")
            print(f"  task_index: {self.task_index_col}")
    
    def _build_episodes(self, max_episodes):
        if not self.episode_col or self.episode_col not in self.data.columns:
            return [{'episode_index': 0, 'start': 0, 'end': len(self.data) - 1}]
        
        episodes = []
        unique_eps = sorted(self.data[self.episode_col].unique())
        if max_episodes:
            unique_eps = unique_eps[:max_episodes]
        
        for ep_idx in unique_eps:
            indices = self.data.index[self.data[self.episode_col] == ep_idx]
            episodes.append({
                'episode_index': ep_idx, 
                'start': indices.min(), 
                'end': indices.max()
            })
        return episodes
    
    def get_task_description(self, task_index: Any) -> str:
        """
        æ ¹æ® task_index è·å–ä»»åŠ¡æè¿°
        """
        if task_index is None:
            return "perform the task"
        
        try:
            idx = int(task_index)
            if idx in self.task_map:
                return self.task_map[idx]
            else:
                return f"perform task {idx}"
        except (ValueError, TypeError):
            return "perform the task"
    
    def get_sample(self, idx: int) -> Dict[str, Any]:
        """
        è·å–å•ä¸ªæ ·æœ¬ï¼Œæ ¼å¼åŒ–ä¸º CALVIN policy æœŸæœ›çš„è¾“å…¥
        """
        row = self.data.iloc[idx]
        
        # æ„å»º images å­—å…¸
        images = {}
        
        if self.base_image_col:
            images["base_0_rgb"] = parse_image(row[self.base_image_col], self.dataset_path)
        else:
            images["base_0_rgb"] = np.zeros((224, 224, 3), dtype=np.uint8)
        
        if self.left_wrist_col:
            images["left_wrist_0_rgb"] = parse_image(row[self.left_wrist_col], self.dataset_path)
        else:
            images["left_wrist_0_rgb"] = np.zeros((224, 224, 3), dtype=np.uint8)
        
        if self.right_wrist_col:
            images["right_wrist_0_rgb"] = parse_image(row[self.right_wrist_col], self.dataset_path)
        else:
            images["right_wrist_0_rgb"] = np.zeros((224, 224, 3), dtype=np.uint8)
        
        # çŠ¶æ€
        if self.state_col:
            state = parse_array(row[self.state_col], 32)
        else:
            state = np.zeros(8, dtype=np.float32)
        
        # ä»»åŠ¡æç¤º - ä» task_index è·å–è¯­è¨€æŒ‡ä»¤
        prompt = "perform the task"
        if self.task_index_col and self.task_index_col in self.data.columns:
            task_idx = row[self.task_index_col]
            prompt = self.get_task_description(task_idx)
        
        # æ„å»ºè¿”å›å­—å…¸
        sample = {
            "images": images,
            "state": state,
            "prompt": prompt,
        }
        
        # ä¿å­˜ GT action ç”¨äºè¯„ä¼°
        if self.action_col:
            sample["gt_action"] = parse_array(row[self.action_col], 7)
        
        # ä¿å­˜ task_index ç”¨äºåˆ†æ
        if self.task_index_col and self.task_index_col in self.data.columns:
            sample["task_index"] = row[self.task_index_col]
        
        return sample
    
    def get_evaluation_samples(
        self, 
        action_horizon: int = 10, 
        num_samples: int = None,
        skip_interval: int = 1
    ) -> Tuple[List[Dict], np.ndarray]:
        """è·å–è¯„ä¼°æ ·æœ¬"""
        samples = []
        gt_trajectories = []
        
        for ep in tqdm(self.episodes, desc="æå–æ ·æœ¬", disable=not self.verbose):
            for start_idx in range(ep['start'], ep['end'] - action_horizon + 1, skip_interval):
                if start_idx + action_horizon > ep['end']:
                    break
                
                # è·å–è¾“å…¥æ ·æœ¬
                sample = self.get_sample(start_idx)
                
                # GT è½¨è¿¹
                gt_actions = []
                for i in range(action_horizon):
                    action = self.data.iloc[start_idx + i][self.action_col]
                    gt_actions.append(parse_array(action, 7))
                
                samples.append(sample)
                gt_trajectories.append(np.stack(gt_actions))
                
                if num_samples and len(samples) >= num_samples:
                    break
            
            if num_samples and len(samples) >= num_samples:
                break
        
        return samples, np.stack(gt_trajectories)


# ============================================================================
# æ¨ç†å‡½æ•°
# ============================================================================

def run_inference(
    policy,
    samples: List[Dict],
    action_horizon: int,
    action_dim: int = 7,
    show_progress: bool = True
) -> Tuple[np.ndarray, int]:
    """è¿è¡Œæ¨¡å‹æ¨ç†"""
    predictions = []
    num_errors = 0
    
    iterator = tqdm(samples, desc="æ¨ç†") if show_progress else samples
    
    for sample in iterator:
        try:
            # è¾“å…¥æ ¼å¼: {"images": {...}, "state": ..., "prompt": ...}
            input_dict = {
                "images": sample["images"],
                "state": sample["state"],
                "prompt": sample["prompt"],
            }
            
            # è°ƒç”¨æ¨ç†
            result = policy.infer(input_dict)
            actions = np.array(result['actions'])
            
            # è°ƒæ•´é•¿åº¦
            if len(actions) >= action_horizon:
                actions = actions[:action_horizon]
            else:
                pad_len = action_horizon - len(actions)
                actions = np.concatenate([actions, np.tile(actions[-1:], (pad_len, 1))])
            
            # è°ƒæ•´ç»´åº¦
            if actions.shape[-1] < action_dim:
                pad = np.zeros((action_horizon, action_dim - actions.shape[-1]))
                actions = np.concatenate([actions, pad], axis=-1)
            else:
                actions = actions[..., :action_dim]
            
            predictions.append(actions)
            
        except Exception as e:
            num_errors += 1
            if num_errors <= 3:
                print(f"\næ¨ç†é”™è¯¯: {e}")
            predictions.append(np.zeros((action_horizon, action_dim), dtype=np.float32))
    
    return np.stack(predictions), num_errors


# ============================================================================
# ä¸»è¯„ä¼°å‡½æ•°
# ============================================================================

def run_evaluation(
    checkpoint_dir: str,
    dataset_path: str,
    config_name: str = "pi0_calvin_scratch",
    num_samples: int = 100,
    action_horizon: int = 10,
    skip_interval: int = 10,
    output_dir: str = None,
    output_filename: str = None,
    verbose: bool = True,
):
    """è¿è¡Œå®Œæ•´è¯„ä¼°"""
    
    from openpi.training import config as _config
    from openpi.policies import policy_config as _policy_config
    
    if verbose:
        print("\n" + "=" * 70)
        print(" Pi0 CALVIN çœŸå®æ¨ç†è¯„ä¼° (æ”¯æŒè¯­è¨€æŒ‡ä»¤)")
        print("=" * 70)
    
    # 1. åŠ è½½ç­–ç•¥
    if verbose:
        print("\nã€1ã€‘åŠ è½½ç­–ç•¥...")
    
    config = _config.get_config(config_name)
    
    if verbose:
        print(f"é…ç½®: {config_name}")
        print(f"  action_dim: {config.model.action_dim}")
        print(f"  action_horizon: {config.model.action_horizon}")
    
    try:
        policy = _policy_config.create_trained_policy(config, checkpoint_dir)
        if verbose:
            print("âœ“ ç­–ç•¥åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç­–ç•¥åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # 2. åŠ è½½æ•°æ®é›†
    if verbose:
        print("\nã€2ã€‘åŠ è½½æ•°æ®é›†...")
    
    dataset = CALVINEvalDataset(
        dataset_path, 
        max_episodes=num_samples * 2,
        verbose=verbose
    )
    
    # 3. æå–æ ·æœ¬
    if verbose:
        print("\nã€3ã€‘æå–è¯„ä¼°æ ·æœ¬...")
    
    samples, gt_trajectories = dataset.get_evaluation_samples(
        action_horizon=action_horizon,
        num_samples=num_samples,
        skip_interval=skip_interval
    )
    
    if verbose:
        print(f"è¯„ä¼°æ ·æœ¬æ•°: {len(samples)}")
        print(f"GT è½¨è¿¹å½¢çŠ¶: {gt_trajectories.shape}")
        
        # æ‰“å°ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼
        s = samples[0]
        print(f"\næ ·æœ¬æ ¼å¼:")
        print(f"  images.base_0_rgb: {s['images']['base_0_rgb'].shape}, {s['images']['base_0_rgb'].dtype}")
        print(f"  images.left_wrist_0_rgb: {s['images']['left_wrist_0_rgb'].shape}")
        print(f"  state: {s['state'].shape}, {s['state'].dtype}")
        print(f"  prompt: \"{s['prompt']}\"")
        
        # ç»Ÿè®¡ä»»åŠ¡åˆ†å¸ƒ
        if 'task_index' in samples[0]:
            task_counts = {}
            for samp in samples:
                t = samp.get('task_index', -1)
                task_counts[t] = task_counts.get(t, 0) + 1
            print(f"\nä»»åŠ¡åˆ†å¸ƒ (å‰5ä¸ª):")
            for t, c in sorted(task_counts.items(), key=lambda x: -x[1])[:5]:
                desc = dataset.get_task_description(t)
                print(f"  [{t}] {desc}: {c} æ ·æœ¬")
    
    # 4. æ¨ç†
    if verbose:
        print("\nã€4ã€‘è¿è¡Œæ¨¡å‹æ¨ç†...")
    
    action_dim = gt_trajectories.shape[-1]
    pred_trajectories, num_errors = run_inference(
        policy=policy,
        samples=samples,
        action_horizon=action_horizon,
        action_dim=action_dim,
        show_progress=verbose
    )
    
    if verbose:
        print(f"\né¢„æµ‹è½¨è¿¹å½¢çŠ¶: {pred_trajectories.shape}")
        if num_errors > 0:
            print(f"âš  {num_errors} ä¸ªæ ·æœ¬æ¨ç†å‡ºé”™")
        else:
            print("âœ“ æ‰€æœ‰æ ·æœ¬æ¨ç†æˆåŠŸ")
    
    # 5. è®¡ç®—æŒ‡æ ‡
    if verbose:
        print("\nã€5ã€‘è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    
    min_dim = min(pred_trajectories.shape[-1], gt_trajectories.shape[-1])
    metrics = evaluate_trajectory_np(
        pred_trajectories[..., :min_dim], 
        gt_trajectories[..., :min_dim]
    )
    
    # 6. æ‰“å°ç»“æœ
    if verbose:
        print("\n" + "=" * 70)
        print(" è¯„ä¼°ç»“æœ")
        print("=" * 70)
        
        print("\nğŸ“Š è½¨è¿¹è¯¯å·®:")
        print(f"  MSE:  {metrics['traj_mse']:.6f}")
        print(f"  MAE:  {metrics['traj_mae']:.6f}")
        print(f"  RMSE: {metrics['traj_rmse']:.6f}")
        
        print("\nğŸ“ ä½ç½®è¯¯å·®:")
        print(f"  Position MSE:  {metrics['pos_mse']:.6f}")
        print(f"  Position RMSE: {metrics['pos_rmse_cm']:.2f} cm")
        print(f"  ADE: {metrics['ade_mean_cm']:.2f} cm (median: {metrics['ade_median_cm']:.2f})")
        print(f"  FDE: {metrics['fde_mean_cm']:.2f} cm (median: {metrics['fde_median_cm']:.2f})")
        
        if 'rot_error_mean_deg' in metrics:
            print("\nğŸ”„ æ—‹è½¬è¯¯å·®:")
            print(f"  Mean:   {metrics['rot_error_mean_deg']:.2f}Â°")
            print(f"  Median: {metrics['rot_error_median_deg']:.2f}Â°")
            print(f"  Std:    {metrics['rot_error_std_deg']:.2f}Â°")
            
            print("\nâœ… æˆåŠŸç‡:")
            print(f"  SR (1cm, 2Â°):  {metrics['sr_1cm_2deg']*100:.2f}%")
            print(f"  SR (2cm, 5Â°):  {metrics['sr_2cm_5deg']*100:.2f}%  â† æ¨èæŒ‡æ ‡")
            print(f"  SR (3cm, 10Â°): {metrics['sr_3cm_10deg']*100:.2f}%")
            print(f"  SR (5cm, 15Â°): {metrics['sr_5cm_15deg']*100:.2f}%")
        
        print("\nğŸ“ å„ç»´åº¦ MSE:")
        for key in sorted([k for k in metrics.keys() if k.startswith('mse_')]):
            dim = key.replace('mse_', '')
            print(f"  {dim}: {metrics[key]:.6f}")
    
    # 7. ä¿å­˜ç»“æœ
    if output_dir is None:
        output_dir = Path(OPENPI_ROOT) / 'evaluation' / 'results'
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if output_filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        try:
            checkpoint_name = Path(checkpoint_dir).parts[-2]
            step = Path(checkpoint_dir).name
        except:
            checkpoint_name = "model"
            step = "0"
        output_filename = f"eval_{checkpoint_name}_{step}_{timestamp}.json"
    
    result = {
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "checkpoint_dir": str(checkpoint_dir),
            "dataset_path": str(dataset_path),
            "config_name": config_name,
            "num_samples": len(samples),
            "num_errors": num_errors,
            "action_horizon": action_horizon,
            "inference_mode": "real",
            "has_language_instructions": bool(dataset.task_map),
        },
        "metrics": metrics,
        "summary": {
            "trajectory_mse": metrics.get('traj_mse'),
            "position_mse": metrics.get('pos_mse'),
            "fde_cm": metrics.get('fde_mean_cm'),
            "ade_cm": metrics.get('ade_mean_cm'),
            "rotation_error_deg": metrics.get('rot_error_mean_deg'),
            "success_rate_2cm_5deg": metrics.get('sr_2cm_5deg'),
        }
    }
    
    output_path = output_dir / output_filename
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    if verbose:
        print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    # åˆ›å»ºæœ€æ–°ç»“æœé“¾æ¥
    latest_path = output_dir / "latest_eval.json"
    try:
        if latest_path.exists() or latest_path.is_symlink():
            latest_path.unlink()
        latest_path.symlink_to(output_path.name)
    except:
        import shutil
        shutil.copy(output_path, latest_path)
    
    if verbose:
        print("=" * 70)
    
    return metrics


# ============================================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================================

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Pi0 CALVIN è¯„ä¼° (æ”¯æŒè¯­è¨€æŒ‡ä»¤)')
    parser.add_argument('--checkpoint_dir', type=str, required=True,
                        help='æ£€æŸ¥ç‚¹ç›®å½•')
    parser.add_argument('--dataset_path', type=str, required=True,
                        help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--config_name', type=str, default='pi0_calvin_scratch',
                        help='é…ç½®åç§°')
    parser.add_argument('--num_samples', type=int, default=100,
                        help='è¯„ä¼°æ ·æœ¬æ•°')
    parser.add_argument('--action_horizon', type=int, default=10,
                        help='åŠ¨ä½œåºåˆ—é•¿åº¦')
    parser.add_argument('--skip_interval', type=int, default=10,
                        help='é‡‡æ ·é—´éš”')
    parser.add_argument('--output_dir', type=str, default=None,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--output_filename', type=str, default=None,
                        help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--quiet', action='store_true',
                        help='å‡å°‘è¾“å‡º')
    
    args = parser.parse_args()
    
    run_evaluation(
        checkpoint_dir=args.checkpoint_dir,
        dataset_path=args.dataset_path,
        config_name=args.config_name,
        num_samples=args.num_samples,
        action_horizon=args.action_horizon,
        skip_interval=args.skip_interval,
        output_dir=args.output_dir,
        output_filename=args.output_filename,
        verbose=not args.quiet,
    )